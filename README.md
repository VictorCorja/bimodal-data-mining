Bimodal Analysis of Key Data and Semantics

<div style="text-align: right">This research was aimed at combining these individual methodologies into a consolidated model that takes in data in both audio and text format. For each desired function, models were selected and ranked by adherence to criteria which determined their applicability to the desired product. Upon selection of the models, they were implemented through libraries into a consolidated program, which took as an input a combinatorial text and audio dataset, and provided a report of the analysis resulting from data mining. The program was tested using data from TED talks, performed text mining and semantic analysis, and provided a structured output of the generated statistics.</div>

This work was based on code in the following repositories:
<ul>
<li>https://github.com/wblgers/hmm_speech_recognition_demo</li>
<li>https://github.com/bjherger/Easy-Latent-Dirichlet-Allocation</li>
<li>https://github.com/susanli2016/NLP-with-Python</li>
<li>https://github.com/Uberi/speech_recognition</li>
<li>https://github.com/aman2656/text2emotion-library</li>
</ul>

Authors:
<ul>
<li>Victor Corja - George Mason University - Virginia, USA - vcorja2@gmu.edu</li>
<li>Austin Crow - George Mason University - Virginia, USA - acrow3@gmu.edu</li>
<li>Nannan Liu - George Mason University - Virginia, USA - nliu6@gmu.edu</li>
<li>Ebrima Ceesay - George Mason University - Virginia, USA - eceesay2@gmu.edu</li>
<li>Maryam Heidari - George Mason University - Virginia, USA - mheidari@gmu.edu</li>
</ul>
